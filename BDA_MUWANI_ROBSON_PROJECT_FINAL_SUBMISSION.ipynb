{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION MODEL IN SPARK APACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    " \n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession\\\n",
    ".builder\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/insurance_data.csv',\n",
    "                       header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- smoker_encoded: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- bmi: double (nullable = true)\n",
      " |-- children: integer (nullable = true)\n",
      " |-- sex_encoded: double (nullable = true)\n",
      " |-- charges: double (nullable = true)\n",
      " |-- region_encoded: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=19, sex='female', bmi=27.9, children=0, smoker='yes', region='southwest', charges=16884.924),\n",
       " Row(age=18, sex='male', bmi=33.77, children=1, smoker='no', region='southeast', charges=1725.5523),\n",
       " Row(age=28, sex='male', bmi=33.0, children=3, smoker='no', region='southeast', charges=4449.462),\n",
       " Row(age=33, sex='male', bmi=22.705, children=0, smoker='no', region='northwest', charges=21984.47061),\n",
       " Row(age=32, sex='male', bmi=28.88, children=0, smoker='no', region='northwest', charges=3866.8552)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of cells in column age with null values: 0\n",
      "no. of cells in column sex with null values: 0\n",
      "no. of cells in column bmi with null values: 0\n",
      "no. of cells in column children with null values: 0\n",
      "no. of cells in column smoker with null values: 0\n",
      "no. of cells in column region with null values: 0\n",
      "no. of cells in column charges with null values: 0\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(\"no. of cells in column\", col, \"with null values:\",\n",
    "          df.filter(df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+--------+------+---------+---------+-----------+--------------+--------------+\n",
      "|age|   sex|  bmi|children|smoker|   region|  charges|sex_encoded|smoker_encoded|region_encoded|\n",
      "+---+------+-----+--------+------+---------+---------+-----------+--------------+--------------+\n",
      "| 19|female| 27.9|       0|   yes|southwest|16884.924|        1.0|           1.0|           1.0|\n",
      "| 18|  male|33.77|       1|    no|southeast|1725.5523|        0.0|           0.0|           0.0|\n",
      "| 28|  male| 33.0|       3|    no|southeast| 4449.462|        0.0|           0.0|           0.0|\n",
      "+---+------+-----+--------+------+---------+---------+-----------+--------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Label encoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexed = df\n",
    "for col in [\"sex\",\"smoker\",\"region\"]:\n",
    "    stringIndexer = StringIndexer(inputCol=col, outputCol=col+\"_encoded\")\n",
    "    model = stringIndexer.fit(indexed)\n",
    "    indexed = model.transform(indexed)\n",
    "indexed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+-----+--------+-----------+---------+--------------+\n",
      "|smoker_encoded|age|  bmi|children|sex_encoded|  charges|region_encoded|\n",
      "+--------------+---+-----+--------+-----------+---------+--------------+\n",
      "|           1.0| 19| 27.9|       0|        1.0|16884.924|           1.0|\n",
      "|           0.0| 18|33.77|       1|        0.0|1725.5523|           0.0|\n",
      "|           0.0| 28| 33.0|       3|        0.0| 4449.462|           0.0|\n",
      "+--------------+---+-----+--------+-----------+---------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = indexed.select(indexed.smoker_encoded,indexed.age, indexed.bmi, indexed.children, \n",
    "                    indexed.sex_encoded,indexed.charges,indexed.region_encoded)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "featurecols = df.columns[1:]\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "assembler = VectorAssembler(inputCols=featurecols, \n",
    "                            outputCol=\"features\")\n",
    "df_feature_vec=assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(smoker_encoded=0.0, scaledFeatures=DenseVector([-1.4914, -2.369, -0.8953, -0.9948, -0.9403, 1.3722])),\n",
       " Row(smoker_encoded=0.0, scaledFeatures=DenseVector([-1.4914, -1.5905, -0.8953, 1.0043, -0.9476, -1.2851])),\n",
       " Row(smoker_encoded=0.0, scaledFeatures=DenseVector([-1.4914, -1.4809, -0.8953, -0.9948, -0.9397, 1.3722]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = df_feature_vec.randomSplit([.8,.2],seed=1)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(train_data)\n",
    "scaledData = scalerModel.transform(train_data)\n",
    "scaledData_test = scalerModel.transform(test_data)\n",
    "scaledData.select(\"smoker_encoded\",\"scaledFeatures\").take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"scaledFeatures\",labelCol=\"smoker_encoded\")\n",
    "lr = LogisticRegression(labelCol=\"smoker_encoded\", featuresCol=\"scaledFeatures\",maxIter=10)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.aggregationDepth,[2,5,10])\\\n",
    "    .addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.fitIntercept,[False, True])\\\n",
    "    .addGrid(lr.maxIter,[10, 100, 1000])\\\n",
    "    .addGrid(lr.regParam,[0.01, 0.5, 2.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set after CV  is 0.511649788880656\n",
      "The area under ROC for test set after CV  is 0.47285409073771545\n"
     ]
    }
   ],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(scaledData)\n",
    "predict_train=cvModel.transform(scaledData)\n",
    "predict_test=cvModel.transform(scaledData_test)\n",
    "print(\"The area under ROC for train set after CV  is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set after CV  is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------+--------------------+\n",
      "|smoker_encoded|       rawPrediction|prediction|         probability|\n",
      "+--------------+--------------------+----------+--------------------+\n",
      "|           0.0|[1.20585478779220...|       0.0|[0.76956467984901...|\n",
      "|           0.0|[1.26482148171884...|       0.0|[0.77985498230114...|\n",
      "|           0.0|[1.29860471228702...|       0.0|[0.78560006475281...|\n",
      "|           0.0|[1.12134448782214...|       0.0|[0.75423801996374...|\n",
      "|           0.0|[1.17427716603809...|       0.0|[0.76391726324050...|\n",
      "+--------------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"scaledFeatures\",\\\n",
    "                                        labelCol=\"smoker_encoded\")\n",
    "predict_test.select(\"smoker_encoded\",\"rawPrediction\",\"prediction\",\\\n",
    "                    \"probability\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9209621993127147\n",
      "0.9209621993127147\n",
      "0.9398983390607102\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy=evaluator.evaluate(predict_test)\n",
    "print(accuracy)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall=evaluator.evaluate(predict_test)\n",
    "print(recall)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision=evaluator.evaluate(predict_test)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+\n",
      "|smoker_encoded|prediction|         probability|\n",
      "+--------------+----------+--------------------+\n",
      "|           0.0|       0.0|[0.76956467984901...|\n",
      "|           0.0|       0.0|[0.77985498230114...|\n",
      "|           0.0|       0.0|[0.78560006475281...|\n",
      "|           0.0|       0.0|[0.75423801996374...|\n",
      "|           0.0|       0.0|[0.76391726324050...|\n",
      "+--------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select(['smoker_encoded','prediction', 'probability']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+\n",
      "|smoker_encoded|prediction|count|\n",
      "+--------------+----------+-----+\n",
      "|           0.0|       0.0|  195|\n",
      "|           0.0|       1.0|   23|\n",
      "|           1.0|       1.0|   73|\n",
      "+--------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select('smoker_encoded','prediction').\\\n",
    "groupby('smoker_encoded','prediction').count().\\\n",
    "sort('prediction').sort('smoker_encoded').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"smoker_encoded\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "             .addGrid(rf.maxDepth, [2, 6])\\\n",
    "             .addGrid(rf.numTrees, [5, 20])\\\n",
    "             .build())\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "cvModel = cv.fit(scaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966692651537049"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions_rf = cvModel.transform(scaledData_test)\n",
    "evaluator.evaluate(predictions_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9656357388316151\n",
      "0.9656357388316151\n",
      "0.966692651537049\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy=evaluator.evaluate(predictions_rf)\n",
    "print(accuracy)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall=evaluator.evaluate(predictions_rf)\n",
    "print(recall)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"smoker_encoded\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision=evaluator.evaluate(predictions_rf)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+\n",
      "|smoker_encoded|prediction|         probability|\n",
      "+--------------+----------+--------------------+\n",
      "|           0.0|       0.0|       [0.992,0.008]|\n",
      "|           0.0|       0.0|[0.99930232558139...|\n",
      "|           0.0|       0.0|[0.98076923076923...|\n",
      "|           0.0|       0.0|           [1.0,0.0]|\n",
      "|           0.0|       0.0|           [1.0,0.0]|\n",
      "+--------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.select(['smoker_encoded','prediction', 'probability']).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----+\n",
      "|smoker_encoded|prediction|count|\n",
      "+--------------+----------+-----+\n",
      "|           0.0|       1.0|    7|\n",
      "|           0.0|       0.0|  211|\n",
      "|           1.0|       1.0|   70|\n",
      "|           1.0|       0.0|    3|\n",
      "+--------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rf.select('smoker_encoded','prediction').\\\n",
    "groupby('smoker_encoded','prediction').count().\\\n",
    "sort('prediction').sort('smoker_encoded').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
